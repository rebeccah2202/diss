{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebeccah2202/diss/blob/main/nc_file_bylakeid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtudqvSGoDPL",
        "outputId": "af155b8b-e302-4276-c786-119fbc721492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.5.tar.gz (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: netCDF4\n",
            "  Building wheel for netCDF4 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netCDF4: filename=netCDF4-1.6.5-cp310-cp310-linux_x86_64.whl size=2590607 sha256=b045327a1b1d89a9fc10a2c0fac6164ff73218b6fbbb92ced19a1379ab997d3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pr0qcpsy/wheels/f0/9e/3d/ac311399c51eb3fc265c78aafe1447d7b4f0f577704bb84dc9\n",
            "Successfully built netCDF4\n",
            "Installing collected packages: netCDF4\n",
            "Successfully installed netCDF4-1.6.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps --no-cache-dir netCDF4 --no-binary netCDF4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RcTnSmZk2ve",
        "outputId": "a852c205-d07b-4eb4-9b5c-2203a514f4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (1.6.3)\n",
            "Requirement already satisfied: numpy>1.13.3 in /usr/local/lib/python3.10/dist-packages (from cftime) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install cftime\n",
        "import os\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import datetime\n",
        "import netCDF4 as nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyNUUn3QoQUO"
      },
      "outputs": [],
      "source": [
        "###########################################################################################\n",
        "# input parameters\n",
        "###########################################################################################\n",
        "\n",
        "# lakes mask file\n",
        "maskfile = 'ESA_CCI_static_lake_mask_v2.0.1.nc'\n",
        "\n",
        "import os\n",
        "if not os.path.exists(maskfile):\n",
        "  !wget https://dap.ceda.ac.uk/neodc/esacci/lakes/data/lake_products/L3S/v2.0.1/ESA_CCI_static_lake_mask_v2.0.1.nc\n",
        "\n",
        "# lake ID\n",
        "lake_id = 12262\n",
        "\n",
        "# defining the period of time in string format: YYYY-MM-DD\n",
        "# dates values must be between 1992-09-26 and 2020-12-31\n",
        "mindate = '2018-04-01'\n",
        "maxdate = '2018-09-30'\n",
        "\n",
        "# version dataset (2.0.2 is the version published in July 2022)\n",
        "version = '2.0.2'\n",
        "\n",
        "# output\n",
        "outdir = 'output/Leven'\n",
        "outprefix = 'Leven_'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn7glvYLoRbl"
      },
      "outputs": [],
      "source": [
        "# test if dates are in the temporal coverage\n",
        "\n",
        "mindate = datetime.datetime.strptime(mindate, '%Y-%m-%d')\n",
        "maxdate = datetime.datetime.strptime(maxdate, '%Y-%m-%d')\n",
        "mindate = max([mindate, datetime.datetime(1992,9,26)])\n",
        "maxdate = min([maxdate, datetime.datetime(2020,12,31)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqZ9tmutod4B"
      },
      "outputs": [],
      "source": [
        "# create the output directory if it does not exist\n",
        "if os.path.exists(outdir)==False:\n",
        "    os.makedirs(outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzAJybWvogul"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# create mask base on lake_id\n",
        "###################################################################\n",
        "\n",
        "mask_nc = nc.Dataset(maskfile)\n",
        "\n",
        "mask_ind  = np.where(mask_nc.variables['CCI_lakeid'][:] == lake_id)\n",
        "minx = np.min(mask_ind[1][:]) - 1\n",
        "maxx = np.max(mask_ind[1][:]) + 1\n",
        "\n",
        "miny = np.min(mask_ind[0][:]) - 1\n",
        "maxy = np.max(mask_ind[0][:]) + 1\n",
        "\n",
        "mask_lake = mask_nc.variables['CCI_lakeid'][miny:maxy+1, minx:maxx+1].data\n",
        "mask_lake[mask_lake!=lake_id] = 0\n",
        "mask_lake[mask_lake == lake_id] = 1\n",
        "\n",
        "mask_nc.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84GmsFZ-ojkr",
        "outputId": "35120419-0f07-4886-f1e5-69854cd40c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download process took 3810.57 seconds.\n"
          ]
        }
      ],
      "source": [
        "# The download process\n",
        "import time\n",
        "\n",
        "# Output file path\n",
        "output_file = f'{outdir}/{outprefix}ESACCI-LAKES-L3S-LK_PRODUCTS-MERGED-{mindate.strftime(\"%Y%m%d\")}_to_{maxdate.strftime(\"%Y%m%d\")}-fv{version}.nc'\n",
        "\n",
        "# Create an empty dataset to store the merged data\n",
        "merged_dataset = None\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop over the dates\n",
        "for data_date in np.arange(mindate.toordinal(), maxdate.toordinal()+1):\n",
        "    current_date = datetime.datetime.fromordinal(data_date)\n",
        "    date_str = current_date.strftime(\"%Y%m%d\")\n",
        "    #print (f'Downloading data from lake_id {lake_id} -  ESACCI-LAKES-L3S-LK_PRODUCTS-MERGED-{date_str}-fv{version}.nc')\n",
        "\n",
        "    path  = f'https://data.cci.ceda.ac.uk/thredds/dodsC/esacci/lakes/data/lake_products/L3S/v{version}/'\n",
        "    path += f'{current_date.year}/{current_date.month:02}/'\n",
        "    path += f'ESACCI-LAKES-L3S-LK_PRODUCTS-MERGED-{date_str}-fv{version}.nc'\n",
        "\n",
        "    dataset = xr.open_dataset(path)\n",
        "    dataset = dataset.isel(lat=slice(miny, maxy+1), lon=slice(minx, maxx+1))\n",
        "\n",
        "    # apply mask only for variables with three dimensions: time, lat, lon\n",
        "    for var in dataset.data_vars:\n",
        "        if len(dataset[var].dims) == 3:\n",
        "            filval = dataset[var].encoding['_FillValue']\n",
        "            data = dataset[var][0, :, :].values\n",
        "            data[mask_lake == 0] = filval\n",
        "            dataset[var][0, :, :] = data\n",
        "\n",
        "    # Merge datasets\n",
        "    if merged_dataset is None:\n",
        "        merged_dataset = dataset\n",
        "    else:\n",
        "        merged_dataset = xr.concat([merged_dataset, dataset], dim='time')\n",
        "\n",
        "# Save the merged dataset to a single file\n",
        "merged_dataset.to_netcdf(output_file)\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Download process took {elapsed_time:.2f} seconds.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj+72A/LVuNg2p5MJt17YR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}